{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"time_series_lstm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOWtylT7h+ouWeevgwZ9cp/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5cBP_lFZCHt","executionInfo":{"status":"ok","timestamp":1628386953263,"user_tz":-240,"elapsed":466555,"user":{"displayName":"Umid Suleymanov","photoUrl":"","userId":"05455467381298754802"}},"outputId":"30342feb-39f1-428b-b055-0949f0da7a83"},"source":["# ======================================================================\n","# There are 5 questions in this exam with increasing difficulty from 1-5.\n","# Please note that the weight of the grade for the question is relative\n","# to its difficulty. So your Category 1 question will score significantly\n","# less than your Category 5 question.\n","#\n","# Don't use lambda layers in your model.\n","# You do not need them to solve the question.\n","# Lambda layers are not supported by the grading infrastructure.\n","#\n","# You must use the Submit and Test button to submit your model\n","# at least once in this category before you finally submit your exam,\n","# otherwise you will score zero for this category.\n","# ======================================================================\n","# QUESTION\n","#\n","# Build and train a neural network to predict sunspot activity using\n","# the Sunspots.csv dataset.\n","#\n","# Your neural network must have an MAE of 0.12 or less on the normalized dataset\n","# for top marks.\n","#\n","# Code for normalizing the data is provided and should not be changed.\n","#\n","# At the bottom of this file, we provide  some testing\n","# code in case you want to check your model.\n","\n","# Note: Do not use lambda layers in your model, they are not supported\n","# on the grading infrastructure.\n","\n","\n","import csv\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","\n","# DO NOT CHANGE THIS CODE\n","def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    series = tf.expand_dims(series, axis=-1)\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n","    ds = ds.shuffle(shuffle_buffer)\n","    ds = ds.map(lambda w: (w[:-1], w[1:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","def solution_model():\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv'\n","    urllib.request.urlretrieve(url, 'sunspots.csv')\n","\n","    time_step = []\n","    sunspots = []\n","\n","    with open('sunspots.csv') as csvfile:\n","      reader = csv.reader(csvfile, delimiter=',')\n","      next(reader)\n","      for row in reader:\n","        sunspots.append(float(row[2]))\n","        time_step.append(int(row[0]))\n","\n","    series = np.array(sunspots) # YOUR CODE HERE\n","\n","    # DO NOT CHANGE THIS CODE\n","    # This is the normalization function\n","    min = np.min(series)\n","    max = np.max(series)\n","    series -= min\n","    series /= max\n","    time = np.array(time_step)\n","\n","    # The data should be split into training and validation sets at time step 3000\n","    # DO NOT CHANGE THIS CODE\n","    split_time = 3000\n","\n","\n","    time_train = time[:split_time]# YOUR CODE HERE\n","    x_train = series[:split_time]# YOUR CODE HERE\n","    time_valid = time[split_time:]# YOUR CODE HERE\n","    x_valid = series[split_time:]#YOUR CODE HERE\n","\n","    # DO NOT CHANGE THIS CODE\n","    window_size = 30\n","    batch_size = 32\n","    shuffle_buffer_size = 1000\n","\n","\n","    train_set = windowed_dataset(x_train, window_size=window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n","\n","\n","    model = tf.keras.models.Sequential([\n","                      tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n","              strides=1, padding=\"causal\",\n","              activation=\"relu\",\n","              input_shape=[None, 1]),\n","        tf.keras.layers.LSTM(62, return_sequences=True),\n","        tf.keras.layers.LSTM(62, return_sequences=True),\n","        tf.keras.layers.Dense(30, activation=\"relu\"),\n","        tf.keras.layers.Dense(10, activation=\"relu\"),\n","\n","      # YOUR CODE HERE. Whatever your first layer is, the input shape will be [None,1] when using the Windowed_dataset above, depending on the layer type chosen\n","      tf.keras.layers.Dense(1)\n","    ])\n","    # PLEASE NOTE IF YOU SEE THIS TEXT WHILE TRAINING -- IT IS SAFE TO IGNORE\n","    # BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n","    # \t [[{{node IteratorGetNext}}]]\n","    #\n","\n","\n","    # YOUR CODE HERE TO COMPILE AND TRAIN THE MODEL\n","\n","    model.compile(loss='mae', optimizer='adam')\n","    model.fit(train_set, batch_size=256, epochs=100)\n","\n","    return model\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, your saved .h5 model will\n","# be sent to the testing infrastructure for scoring\n","# and the score will be returned to you.\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"mymodel.h5\")\n","\n","\n","\n","# THIS CODE IS USED IN THE TESTER FOR FORECASTING. IF YOU WANT TO TEST YOUR MODEL\n","# BEFORE UPLOADING YOU CAN DO IT WITH THIS\n","#def model_forecast(model, series, window_size):\n","#    ds = tf.data.Dataset.from_tensor_slices(series)\n","#    ds = ds.window(window_size, shift=1, drop_remainder=True)\n","#    ds = ds.flat_map(lambda w: w.batch(window_size))\n","#    ds = ds.batch(32).prefetch(1)\n","#    forecast = model.predict(ds)\n","#    return forecast\n","\n","\n","#window_size = # YOUR CODE HERE\n","#rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n","#rnn_forecast = rnn_forecast[split_time - window_size:-1, -1,].ravel()\n","\n","#result = tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()\n","\n","## To get the maximum score, your model must have an MAE OF .12 or less.\n","## When you Submit and Test your model, the grading infrastructure\n","## converts the MAE of your model to a score from 0 to 5 as follows:\n","\n","#test_val = 100 * result\n","#score = math.ceil(17 - test_val)\n","#if score > 5:\n","#    score = 5\n","\n","#print(score)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","93/93 [==============================] - 9s 43ms/step - loss: 0.0744\n","Epoch 2/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0505\n","Epoch 3/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0466\n","Epoch 4/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0456\n","Epoch 5/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0449\n","Epoch 6/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0448\n","Epoch 7/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0450\n","Epoch 8/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0445\n","Epoch 9/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0447\n","Epoch 10/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0447\n","Epoch 11/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0446\n","Epoch 12/100\n","93/93 [==============================] - 4s 45ms/step - loss: 0.0446\n","Epoch 13/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0444\n","Epoch 14/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0444\n","Epoch 15/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0444\n","Epoch 16/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0443\n","Epoch 17/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0442\n","Epoch 18/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0443\n","Epoch 19/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0442\n","Epoch 20/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0440\n","Epoch 21/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0440\n","Epoch 22/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0441\n","Epoch 23/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0441\n","Epoch 24/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0446\n","Epoch 25/100\n","93/93 [==============================] - 4s 45ms/step - loss: 0.0440\n","Epoch 26/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0441\n","Epoch 27/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0439\n","Epoch 28/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0439\n","Epoch 29/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0441\n","Epoch 30/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0440\n","Epoch 31/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0439\n","Epoch 32/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0439\n","Epoch 33/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0437\n","Epoch 34/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0437\n","Epoch 35/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0436\n","Epoch 36/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0436\n","Epoch 37/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0434\n","Epoch 38/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0433\n","Epoch 39/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0432\n","Epoch 40/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0435\n","Epoch 41/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0434\n","Epoch 42/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0431\n","Epoch 43/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0432\n","Epoch 44/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0431\n","Epoch 45/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0429\n","Epoch 46/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0430\n","Epoch 47/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0427\n","Epoch 48/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0427\n","Epoch 49/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0428\n","Epoch 50/100\n","93/93 [==============================] - 4s 46ms/step - loss: 0.0426\n","Epoch 51/100\n","93/93 [==============================] - 4s 46ms/step - loss: 0.0425\n","Epoch 52/100\n","93/93 [==============================] - 4s 45ms/step - loss: 0.0425\n","Epoch 53/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0421\n","Epoch 54/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0421\n","Epoch 55/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0421\n","Epoch 56/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0418\n","Epoch 57/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0418\n","Epoch 58/100\n","93/93 [==============================] - 4s 39ms/step - loss: 0.0417\n","Epoch 59/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0413\n","Epoch 60/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0413\n","Epoch 61/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0409\n","Epoch 62/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0408\n","Epoch 63/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0408\n","Epoch 64/100\n","93/93 [==============================] - 4s 45ms/step - loss: 0.0405\n","Epoch 65/100\n","93/93 [==============================] - 4s 45ms/step - loss: 0.0402\n","Epoch 66/100\n","93/93 [==============================] - 4s 46ms/step - loss: 0.0400\n","Epoch 67/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0399\n","Epoch 68/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0398\n","Epoch 69/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0395\n","Epoch 70/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0391\n","Epoch 71/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0390\n","Epoch 72/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0388\n","Epoch 73/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0385\n","Epoch 74/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0383\n","Epoch 75/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0379\n","Epoch 76/100\n","93/93 [==============================] - 4s 46ms/step - loss: 0.0378\n","Epoch 77/100\n","93/93 [==============================] - 4s 47ms/step - loss: 0.0376\n","Epoch 78/100\n","93/93 [==============================] - 4s 45ms/step - loss: 0.0373\n","Epoch 79/100\n","93/93 [==============================] - 4s 44ms/step - loss: 0.0369\n","Epoch 80/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0367\n","Epoch 81/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0364\n","Epoch 82/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0361\n","Epoch 83/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0359\n","Epoch 84/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0356\n","Epoch 85/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0354\n","Epoch 86/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0353\n","Epoch 87/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0349\n","Epoch 88/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0345\n","Epoch 89/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0344\n","Epoch 90/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0343\n","Epoch 91/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0339\n","Epoch 92/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0336\n","Epoch 93/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0333\n","Epoch 94/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0331\n","Epoch 95/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0332\n","Epoch 96/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0328\n","Epoch 97/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0326\n","Epoch 98/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0323\n","Epoch 99/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0321\n","Epoch 100/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0318\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-eZFgna0ZdKO","executionInfo":{"status":"ok","timestamp":1628386964389,"user_tz":-240,"elapsed":291,"user":{"displayName":"Umid Suleymanov","photoUrl":"","userId":"05455467381298754802"}}},"source":["model.save(\"time_series_with_LSTM.h5\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"DCaQ1o1vbAc6","executionInfo":{"status":"ok","timestamp":1628386964691,"user_tz":-240,"elapsed":9,"user":{"displayName":"Umid Suleymanov","photoUrl":"","userId":"05455467381298754802"}},"outputId":"996e8c1e-fc7c-40f8-982b-86a554780e5c"},"source":["from google.colab import files\n","files.download(\"time_series_with_LSTM.h5\") "],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_065b4dd8-dd74-41f5-9843-97b2ecca52e0\", \"time_series_with_LSTM.h5\", 836128)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"wn9G6qn8bJnf"},"source":[""],"execution_count":null,"outputs":[]}]}